{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wooihaw/practical_ai/blob/main/mnist_lenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgCizfvS69do"
   },
   "source": [
    "# Hands-on 5A\n",
    "## This is a 'Hello World\" example for convolutional neural network (CNN)\n",
    "### In this example, we will build and train a CNN to classify images of handwritten digit\n",
    "<img src=\"http://neupy.com/_images/random-digits.png\" alt=\"MNIST\" width=\"640\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXTGgWG_69dp"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUf16VAb69dt"
   },
   "outputs": [],
   "source": [
    "# Import the relevant Python modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUf16VAb69dt"
   },
   "outputs": [],
   "source": [
    "# Load the dataset and split data into training and test sets\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Display an handwritten digit in the traijning set (change m to display another digit)\n",
    "m = 111\n",
    "plt.axis(False)\n",
    "plt.title(f'Label: {training_labels[m]}')\n",
    "plt.imshow(training_images[m], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUf16VAb69dt"
   },
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUf16VAb69dt"
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(50, (5, 5), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model fitting (train the model using the training set)\n",
    "history = model.fit(training_images, training_labels, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUf16VAb69dt"
   },
   "outputs": [],
   "source": [
    "# Plot the performance of the model\n",
    "plt.plot(history.history['accuracy'], 'b', label='train')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUf16VAb69dt"
   },
   "outputs": [],
   "source": [
    "# Evaluate the performance of the trained model using the test set\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print(f'Loss: {score[0]:.4f}, accuracy: {score[1]:.4f}')\n",
    "\n",
    "# Predict the label of a test image (change n to test another image)\n",
    "n = 911\n",
    "x = np.expand_dims(test_images[n], axis=0)\n",
    "classes = model.predict(x)\n",
    "print(f'Predicted label: {classes.argmax()}')\n",
    "\n",
    "# Display the test image and show the actual label\n",
    "plt.axis(False)\n",
    "plt.title(f'Actual label: {test_labels[n]}')\n",
    "plt.imshow(test_images[n].reshape(28, 28) * 255, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on 5B\n",
    "## Classification of three animals (from scratch)\n",
    "### In this example, we are going to train a CNN model from scratch for the classfication of three animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to /content/\n",
    "cd /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset from Google Drive\n",
    "!tar -xvf \"/content/drive/My Drive/three_animals.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup training images and testing images\n",
    "train_dir = '../Deep_Learning/CNN/Data/three_animals/train'\n",
    "test_dir = '../Deep_Learning/CNN/Data/three_animals/validate/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1/255.,\n",
    "                    rotation_range=30,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    train_dir,\n",
    "                    batch_size=32,\n",
    "                    target_size=(150,150),\n",
    "                    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                    test_dir,\n",
    "                    batch_size=32,\n",
    "                    target_size=(150,150),\n",
    "                    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile and train model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_generator, \n",
    "                    steps_per_epoch=85, \n",
    "                    epochs=5, \n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=10,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model accuracy and lose\n",
    "acc = history.history['acc']\n",
    "loss = history.history['loss']\n",
    "val_acc = history.history['val_acc']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(range(len(acc)), acc, 'b', label='accuracy')\n",
    "plt.plot(range(len(val_acc)), val_acc, 'g', label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model1.json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model1.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "from json import dump\n",
    "with open('class_indices1.json', 'w') as f:\n",
    "  dump(train_generator.class_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model on a new image\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from json import load\n",
    "import numpy as np\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model1.json', 'r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model1.h5\")\n",
    "\n",
    "# load class indices\n",
    "with open('class_indices1.json', 'r') as f:\n",
    "    class_indices = load(f)\n",
    "print(\"Loaded model from disk\")\n",
    "print(class_indices)\n",
    "map2class = {class_indices[k]:k for k in class_indices}\n",
    "\n",
    "# print the predicted class\n",
    "files = ['animal01.jpg', 'animal02.jpg', 'animal03.jpg']\n",
    "for f in files:\n",
    "    img = load_img(f, target_size=(150, 150))\n",
    "    x = img_to_array(img)/255.\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    classes = model.predict(x)\n",
    "    print(f'{f} predicted as {map2class[classes.argmax()]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on 5C\n",
    "## Classification of three animals (with transfer learning)\n",
    "### In this example, we are going to train a CNN model with transfer learning for the classfication of three animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup training images and testing images\n",
    "train_dir = '../Deep_Learning/CNN/Data/three_animals/train'\n",
    "test_dir = '../Deep_Learning/CNN/Data/three_animals/validate/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1/255.,\n",
    "                    rotation_range=40,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    train_dir,\n",
    "                    batch_size=32,\n",
    "                    target_size=(150,150),\n",
    "                    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                    test_dir,\n",
    "                    batch_size=32,\n",
    "                    target_size=(150,150),\n",
    "                    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the inception mode, do not include the fully-connected layer at the top as the last layer of the network\n",
    "base_model = InceptionV3(input_shape=(150, 150, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print the model summary\n",
    "base_model.summary()\n",
    "\n",
    "last_layer = base_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Applies average pooling on the spatial dimensions until each spatial dimension is one\n",
    "x = GlobalAveragePooling2D()(last_output)\n",
    "# Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "x = Dense(512, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = Dropout(0.2)(x)\n",
    "# Add a final sigmoid layer for classification\n",
    "x = Dense(3, activation='softmax')(x)           \n",
    "\n",
    "model = Model(base_model.input, x) \n",
    "\n",
    "model.compile(optimizer ='rmsprop', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_generator, \n",
    "                    steps_per_epoch=85, \n",
    "                    epochs=3, \n",
    "                    validation_data=test_generator, \n",
    "                    validation_steps=10, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model accuracy and lose\n",
    "acc = history.history['acc']\n",
    "loss = history.history['loss']\n",
    "val_acc = history.history['val_acc']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(range(len(acc)), acc, 'b', label='accuracy')\n",
    "plt.plot(range(len(val_acc)), val_acc, 'g', label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model2.json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model2.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "from json import dump\n",
    "with open('class_indices2.json', 'w') as f:\n",
    "  dump(train_generator.class_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model on a new image\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from json import load\n",
    "import numpy as np\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model2.json', 'r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model2.h5\")\n",
    "\n",
    "# load class indices\n",
    "with open('class_indices2.json', 'r') as f:\n",
    "    class_indices = load(f)\n",
    "print(\"Loaded model from disk\")\n",
    "print(class_indices)\n",
    "map2class = {class_indices[k]:k for k in class_indices}\n",
    "\n",
    "# print the predicted class\n",
    "files = ['animal01.jpg', 'animal02.jpg', 'animal03.jpg']\n",
    "for f in files:\n",
    "    img = load_img(f, target_size=(150, 150))\n",
    "    x = img_to_array(img)/255.\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    classes = model.predict(x)\n",
    "    print(f'{f} predicted as {map2class[classes.argmax()]}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "mnist_lenet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
