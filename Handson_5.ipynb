{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mnist_lenet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wooihaw/practical_ai/blob/main/Handson_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgCizfvS69do"
      },
      "source": [
        "# Hands-on 5A\n",
        "## This is a 'Hello World\" example for convolutional neural network (CNN)\n",
        "### In this example, we will build and train a CNN to classify images of handwritten digit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWhDKcQmEkVX"
      },
      "source": [
        "# Create a clone of practical_ai repo\n",
        "!cd /content/\n",
        "!git clone https://github.com/wooihaw/practical_ai.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXTGgWG_69dp"
      },
      "source": [
        "%matplotlib inline\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUf16VAb69dt"
      },
      "source": [
        "# Import the relevant Python modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sicHPEX8ACOr"
      },
      "source": [
        "# Load the dataset and split data into training and test sets\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Display an handwritten digit in the traijning set (change m to display another digit)\n",
        "m = 111\n",
        "plt.axis(False)\n",
        "plt.title(f'Label: {training_labels[m]}')\n",
        "plt.imshow(training_images[m], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzvP1deiACOr"
      },
      "source": [
        "# Preprocessing the data\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IagFI23ACOr"
      },
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(28, 28, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Conv2D(50, (5, 5), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model fitting (train the model using the training set)\n",
        "history = model.fit(training_images, training_labels, validation_data=(test_images, test_labels), epochs=10, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh_xHYAoACOs"
      },
      "source": [
        "# Plot the performance of the model\n",
        "plt.plot(history.history['accuracy'], 'b', label='train')\n",
        "plt.plot(history.history['val_accuracy'], 'g', label='test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], 'b', label='train')\n",
        "plt.plot(history.history['val_loss'], 'g', label='test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance of the trained model using the test set\n",
        "score = model.evaluate(test_images, test_labels)\n",
        "print(f'Loss: {score[0]:.4f}, accuracy: {score[1]:.4f}')"
      ],
      "metadata": {
        "id": "iXDzhEF2XPaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6Y_Fac2ACOs"
      },
      "source": [
        "# Predict the label of a test image (enter an index between 0 and 9999)\n",
        "try:\n",
        "  index = int(input(\"Enter an index between 0 and 9999: \"))\n",
        "  assert 0 <= index < 10000, \"The index should be between 0 and 9999\"\n",
        "except Exception as e:\n",
        "  print(\"Error: \", e)\n",
        "else:\n",
        "  x = np.expand_dims(test_images[index], axis=0)\n",
        "  classes = model.predict(x)\n",
        "  print(f'Predicted label: {classes.argmax()}')\n",
        "\n",
        "  # Display the test image and show the actual label\n",
        "  plt.axis(False)\n",
        "  plt.title(f'Actual label: {test_labels[index]}')\n",
        "  plt.imshow(test_images[index].reshape(28, 28) * 255, cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRs5mpBJACOs"
      },
      "source": [
        "# Hands-on 5B\n",
        "## Classification of three animals (from scratch)\n",
        "### In this example, we are going to train a CNN model from scratch for the classfication of three animals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DncYnUx1ACOs"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy27dMUTACOt"
      },
      "source": [
        "# Extract dataset from Google Drive\n",
        "!cd /content/\n",
        "!tar -xf /content/drive/MyDrive/three_animals.tar.gz > /dev/null && echo \"A total of $(find /content/three_animals/ -type f | wc -l) files have been successfully extracted.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ6zEAm8ACOt"
      },
      "source": [
        "# Load modules\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Setup training images and testing images\n",
        "train_dir = 'three_animals/train'\n",
        "test_dir = 'three_animals/validate/'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1/255.,\n",
        "                    rotation_range=30,\n",
        "                    width_shift_range=0.2,\n",
        "                    height_shift_range=0.2,\n",
        "                    shear_range=0.2,\n",
        "                    zoom_range=0.2,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                    train_dir,\n",
        "                    batch_size=32,\n",
        "                    target_size=(150,150),\n",
        "                    class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "                    test_dir,\n",
        "                    batch_size=32,\n",
        "                    target_size=(150,150),\n",
        "                    class_mode='categorical',\n",
        "                    shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grB6u7m3ACOt"
      },
      "source": [
        "# Construct CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile and train model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=5,\n",
        "                    validation_data=test_generator,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGafn4h1ACOt"
      },
      "source": [
        "# Plot model accuracy and lose\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "val_acc = history.history['val_acc']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.plot(np.arange(1, len(acc) + 1), acc, 'b', label='accuracy')\n",
        "plt.plot(np.arange(1, len(val_acc) + 1), val_acc, 'g', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(np.arange(1, len(acc) + 1))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRVGHoFGYwm_"
      },
      "source": [
        "# Show the confusion matrix\n",
        "pred = model.predict(test_generator)\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "cm = confusion_matrix(test_generator.classes, y_pred)\n",
        "plt.style.use('default')\n",
        "fig = plt.figure()\n",
        "ax = plt.gca()\n",
        "im = ax.matshow(cm)\n",
        "for i, j in enumerate(cm.ravel()):\n",
        "    ax.text(i%3, i//3, f'{j}', color='w', size='large', weight='bold', ha='center')\n",
        "ax.xaxis.set_ticks_position('bottom')\n",
        "ax.set_xticks(np.arange(3))\n",
        "ax.set_xticklabels(list(train_generator.class_indices))\n",
        "ax.set_yticks(np.arange(3))\n",
        "ax.set_yticklabels(list(train_generator.class_indices))\n",
        "ax.set_xlabel('Predicted label')\n",
        "ax.set_ylabel('True label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZMUqAEjACOu"
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model1.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model1.weights.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "from json import dump\n",
        "with open('class_indices1.json', 'w') as f:\n",
        "  dump(train_generator.class_indices, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZG8DkkRACOu"
      },
      "source": [
        "# Test the trained model on a new image\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from json import load\n",
        "import numpy as np\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('model1.json', 'r')\n",
        "model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(model_json)\n",
        "# load weights into new model\n",
        "model.load_weights(\"model1.weights.h5\")\n",
        "\n",
        "# load class indices\n",
        "with open('class_indices1.json', 'r') as f:\n",
        "    class_indices = load(f)\n",
        "print(\"Model loaded from disk\")\n",
        "map2class = {class_indices[k]:k for k in class_indices}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the test image and show the predicted class\n",
        "file = 'practical_ai/animal01.jpg'\n",
        "img = load_img(file, target_size=(150, 150))\n",
        "x = img_to_array(img)/255.\n",
        "x = np.expand_dims(x, axis=0)\n",
        "classes = model.predict(x)\n",
        "for i, k in enumerate(class_indices):\n",
        "  print(f'{k:10}: {classes[0, i]: .3f}')\n",
        "\n",
        "plt.axis(False)\n",
        "plt.imshow(load_img(file))\n",
        "plt.title(f'Predicted as {map2class[classes.argmax()]}', y=0, pad=-10, verticalalignment=\"top\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dsMfLjA9Ztvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H52DH5q0ACOv"
      },
      "source": [
        "# Hands-on 5C\n",
        "## Classification of three animals (with transfer learning)\n",
        "### In this example, we are going to train a CNN model with transfer learning for the classfication of three animals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ODyVM7ZACOv"
      },
      "source": [
        "# Load modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Setup training images and testing images\n",
        "train_dir = 'three_animals/train'\n",
        "test_dir = 'three_animals/validate/'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1/255.,\n",
        "                    rotation_range=40,\n",
        "                    width_shift_range=0.2,\n",
        "                    height_shift_range=0.2,\n",
        "                    shear_range=0.2,\n",
        "                    zoom_range=0.2,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                    train_dir,\n",
        "                    batch_size=32,\n",
        "                    target_size=(150,150),\n",
        "                    class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "                    test_dir,\n",
        "                    batch_size=32,\n",
        "                    target_size=(150,150),\n",
        "                    class_mode='categorical',\n",
        "                    shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSNjLjgVACOv"
      },
      "source": [
        "# Import the inception mode, do not include the fully-connected layer at the top as the last layer of the network\n",
        "base_model = InceptionV3(input_shape=(150, 150, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "last_layer = base_model.get_layer('mixed7')\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Applies average pooling on the spatial dimensions until each spatial dimension is one\n",
        "x = GlobalAveragePooling2D()(last_output)\n",
        "# Add a fully connected layer with 1024 hidden units and ReLU activation\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = Dropout(0.2)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = Model(base_model.input, x)\n",
        "\n",
        "model.compile(optimizer ='rmsprop',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['acc'])\n",
        "\n",
        "# Calculate the number of layers\n",
        "num_layers = len(model.layers)\n",
        "\n",
        "# Calculate the total number of parameters\n",
        "total_params = model.count_params()\n",
        "\n",
        "print(f'Number of layers: {num_layers}')\n",
        "print(f'Total parameters to learn: {total_params}')\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=3,\n",
        "                    validation_data=test_generator,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGfWD2OFACOv"
      },
      "source": [
        "# Plot model accuracy and lose\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "val_acc = history.history['val_acc']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.plot(np.arange(1, len(acc) + 1), acc, 'b', label='accuracy')\n",
        "plt.plot(np.arange(1, len(val_acc) + 1), val_acc, 'g', label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(np.arange(1, len(acc) + 1))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYDtIzD0_ca-"
      },
      "source": [
        "# Show the confusion matrix\n",
        "pred = model.predict(test_generator)\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "cm = confusion_matrix(test_generator.classes, y_pred)\n",
        "plt.style.use('default')\n",
        "fig = plt.figure()\n",
        "ax = plt.gca()\n",
        "im = ax.matshow(cm)\n",
        "for i, j in enumerate(cm.ravel()):\n",
        "    ax.text(i%3, i//3, f'{j}', color='w', size='large', weight='bold', ha='center')\n",
        "ax.xaxis.set_ticks_position('bottom')\n",
        "ax.set_xticks(np.arange(3))\n",
        "ax.set_xticklabels(list(train_generator.class_indices))\n",
        "ax.set_yticks(np.arange(3))\n",
        "ax.set_yticklabels(list(train_generator.class_indices))\n",
        "ax.set_xlabel('Predicted label')\n",
        "ax.set_ylabel('True label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TQgqnBDVHAL"
      },
      "source": [
        "# List files that were missclassified\n",
        "p = test_generator.classes != y_pred\n",
        "file_errors = [test_generator.filenames[i] for i, j in enumerate(p) if j]\n",
        "print(file_errors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJw3jdmMACOw"
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model2.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model2.weights.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "from json import dump\n",
        "with open('class_indices2.json', 'w') as f:\n",
        "  dump(train_generator.class_indices, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXtrO4ghACOw"
      },
      "source": [
        "# Test the trained model on a new image\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from json import load\n",
        "import numpy as np\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('model2.json', 'r')\n",
        "model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(model_json)\n",
        "# load weights into new model\n",
        "model.load_weights(\"model2.weights.h5\")\n",
        "\n",
        "# load class indices\n",
        "with open('class_indices2.json', 'r') as f:\n",
        "    class_indices = load(f)\n",
        "print(\"Model loaded from disk\")\n",
        "map2class = {class_indices[k]:k for k in class_indices}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the test image and show the predicted class\n",
        "file = 'practical_ai/animal01.jpg'\n",
        "img = load_img(file, target_size=(150, 150))\n",
        "x = img_to_array(img)/255.\n",
        "x = np.expand_dims(x, axis=0)\n",
        "classes = model.predict(x)\n",
        "for i, k in enumerate(class_indices):\n",
        "  print(f'{k:10}: {classes[0, i]: .3f}')\n",
        "\n",
        "plt.axis(False)\n",
        "plt.imshow(load_img(file))\n",
        "plt.title(f'Predicted as {map2class[classes.argmax()]}', y=0, pad=-10, verticalalignment=\"top\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q9NKlPHqb5Kc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}